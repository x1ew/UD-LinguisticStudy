{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/x1ew/UD-LinguisticStudy/blob/main/UD_LinguisticStudy.ipynb)"
      ],
      "metadata": {
        "id": "QKo2X8fy-j3I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEDNBsJo8VBt"
      },
      "source": [
        "#***Import Data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6aSsBJD8VMm"
      },
      "outputs": [],
      "source": [
        "!curl --remote-name-all https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-5502{/ud-treebanks-v2.14.tgz,/ud-documentation-v2.14.tgz,/ud-tools-v2.14.tgz}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uENrG-o_olmv"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Extract ud-treebanks-v2.14.tgz\n",
        "tar -xzvf ud-treebanks-v2.14.tgz\n",
        "\n",
        "cd ud-treebanks-v2.14\n",
        "\n",
        "for dir in */; do\n",
        "  # Check if the directory contains at least 3 .conllu files\n",
        "  count=$(find \"$dir\" -maxdepth 1 -type f -name \"*.conllu\" | wc -l)\n",
        "\n",
        "  if [ \"$count\" -lt 3 ]; then\n",
        "    # If fewer than 3 .conllu files, remove the directory\n",
        "    echo \"Removing directory $dir (contains $count .conllu files)\"\n",
        "    rm -rf \"$dir\"\n",
        "  fi\n",
        "done\n",
        "\n",
        "for dir in */; do\n",
        "  if [ -d \"$dir\" ]; then\n",
        "    echo \"Processing directory: $dir\"\n",
        "    # Find all files except .conllu files and delete them\n",
        "    find \"$dir\" -maxdepth 1 -type f ! -name \"*.conllu\" -exec rm -f {} \\;\n",
        "  fi\n",
        "done\n",
        "\n",
        "\n",
        "du -sh * | sort -h | awk '{print $2}' > ../normalized_dir_names.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOpJDpdo_-Yk"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# Extract ud-treebanks-v2.14.tgz\n",
        "# !tar -xzvf ud-treebanks-v2.14.tgz\n",
        "\n",
        "# Extract ud-documentation-v2.14.tgz\n",
        "#!tar -xzvf ud-documentation-v2.14.tgz\n",
        "\n",
        "# Extract ud-tools-v2.14.tgz\n",
        "#!tar -xzvf ud-tools-v2.14.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4iJEfR__-eZ"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYgMBu8-KJe3"
      },
      "outputs": [],
      "source": [
        "!pip install conllu transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6rWAIiqJ5l7",
        "outputId": "7da2d8cc-a7aa-4f68-9db1-7866b3c18b1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeoZlZ2blNbx"
      },
      "source": [
        "#***Dataset Preparation and Baseline Model Training***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezu79h-jlOFf"
      },
      "source": [
        "##***Dataset***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS6Bt3FkpH0w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def sep_file(dir_path, num_countries):\n",
        "    with open('./normalized_dir_names.txt', 'r') as file:\n",
        "      lang_names = [line.strip() for line in file]\n",
        "\n",
        "    # selected_dirs = [os.path.join(dir_path, name) for name in lang_names[:num_countries]]\n",
        "    selected_dirs = [os.path.join(dir_path, name) for name in lang_names[num_countries:num_countries+10]]\n",
        "\n",
        "    l_train, l_test, l_dev = [], [], []\n",
        "    for dir_name in selected_dirs:\n",
        "        for file_name in os.listdir(dir_name):\n",
        "            if file_name.endswith('.conllu'):\n",
        "                if 'train' in file_name:\n",
        "                    l_train.append(os.path.join(dir_name, file_name))\n",
        "                elif 'test' in file_name:\n",
        "                    l_test.append(os.path.join(dir_name, file_name))\n",
        "                elif 'dev' in file_name:\n",
        "                    l_dev.append(os.path.join(dir_name, file_name))\n",
        "\n",
        "    return l_train, l_dev, l_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFvY6Hvpr_Ko"
      },
      "outputs": [],
      "source": [
        "import conllu\n",
        "\n",
        "def prepare_data(files_dir):\n",
        "  all_tokens, all_labels = [], []\n",
        "  for i in files_dir:\n",
        "      with open(i, 'r', encoding='utf-8') as f:\n",
        "          data = conllu.parse(f.read())\n",
        "          # print(data)\n",
        "          for sentence in data:\n",
        "              tokens = [\n",
        "                  token['form'] for token in sentence\n",
        "                  if token['upostag'] not in ['PUNCT', 'ADP', 'DET', 'CCONJ', 'X', '_']\n",
        "                  and token['form'].strip()\n",
        "              ]\n",
        "              labels = [\n",
        "                  token['upostag'] for token in sentence\n",
        "                  if token['upostag'] not in ['PUNCT', 'ADP', 'DET', 'CCONJ', 'X', '_']\n",
        "              ]\n",
        "              if tokens and labels:  # both tokens and labels are non-empty\n",
        "                all_tokens.append(tokens)\n",
        "                all_labels.append(labels)\n",
        "\n",
        "  return all_tokens, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4HGNrCeXrpP",
        "outputId": "3cac91b6-5b8a-408b-82cb-6ecff5931d22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22075"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "l_train, l_dev, l_test  = sep_file(dir_path='/content/ud-treebanks-v2.14', num_countries=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQXgp0Ze45H6"
      },
      "outputs": [],
      "source": [
        "l_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwcrYunmrvKG"
      },
      "outputs": [],
      "source": [
        "def create_mapping_dics(train_labels):\n",
        "  labels = []\n",
        "  for sample in train_labels:\n",
        "    for tag in sample:\n",
        "      if tag not in labels:\n",
        "        labels.append(tag)\n",
        "\n",
        "  label2id = {\n",
        "      \"O\": 0,\n",
        "  }\n",
        "  for i in range(1, len(labels)+1):\n",
        "    label2id[labels[i-1]] = i\n",
        "\n",
        "  id2label = {val: key for key, val in label2id.items()}\n",
        "\n",
        "  return label2id, id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwYRjZqegDoJ"
      },
      "outputs": [],
      "source": [
        "def convert_labels_to_ids(labels, label2id): # labels = [0, 1]\n",
        "  ids = []\n",
        "  for label in labels:\n",
        "    id = []\n",
        "    for each_label in label:\n",
        "      if each_label in label2id.keys():\n",
        "        id.append(label2id[each_label])\n",
        "      else:\n",
        "        id.append(label2id['O'])\n",
        "    ids.append(id)\n",
        "\n",
        "  return ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRhGMX6BtNSw"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(sentences, labels, max_length, tokenizer):\n",
        "    tokenized_inputs = tokenizer(sentences, padding='max_length', truncation=True, max_length=min(512, max_length+2), is_split_into_words=True)\n",
        "\n",
        "    label_all_tokens = True\n",
        "    new_labels = []\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        new_labels.append(label_ids)\n",
        "        # print(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxS9U9TeLpO-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import conllu\n",
        "\n",
        "class UD_Dataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "      self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "      return item # returns ([101, 21934,  4305,  3481,  4276, 102, 0, 0, 0], [-100, 6, 6, 1, 1, -100, -100, -100, -100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLStHbK7L7Gv"
      },
      "outputs": [],
      "source": [
        "# def load_data(l_train, l_dev, l_test, label2id):\n",
        "def load_data(l_train, l_dev, l_test):\n",
        "    train_tokens, train_labels = prepare_data(l_train)\n",
        "    dev_tokens, dev_labels = prepare_data(l_dev)\n",
        "    test_tokens, test_labels = prepare_data(l_test)\n",
        "\n",
        "    label2id, id2label = create_mapping_dics(train_labels)\n",
        "    print('label2id: ', label2id)\n",
        "    print('id2label: ', id2label)\n",
        "\n",
        "    train_label_ids = convert_labels_to_ids(train_labels, label2id)\n",
        "    dev_label_ids = convert_labels_to_ids(dev_labels, label2id)\n",
        "    test_label_ids = convert_labels_to_ids(test_labels, label2id)\n",
        "\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "    max_length = max([len(id) for id in train_label_ids])\n",
        "    # print(max_length)\n",
        "\n",
        "    train_encodings = tokenize_and_align_labels(train_tokens, train_label_ids, max_length, tokenizer)\n",
        "    dev_encodings = tokenize_and_align_labels(dev_tokens, dev_label_ids, max_length, tokenizer)\n",
        "    test_encodings = tokenize_and_align_labels(test_tokens, test_label_ids, max_length, tokenizer)\n",
        "\n",
        "    train_dataset = UD_Dataset(train_encodings)\n",
        "    print(train_dataset[0])\n",
        "    dev_dataset = UD_Dataset(dev_encodings)\n",
        "    test_dataset = UD_Dataset(test_encodings)\n",
        "\n",
        "    return train_dataset, dev_dataset, test_dataset, train_tokens, dev_tokens, test_tokens, label2id, id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJWujiV8s1BX"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel, BertTokenizerFast, AutoTokenizer\n",
        "\n",
        "# train_dataset, dev_dataset, test_dataset, label2id, id2label = load_data(l_train, l_dev, l_test, label2id)\n",
        "train_dataset, dev_dataset, test_dataset, train_tokens, dev_tokens, test_tokens, label2id, id2label = load_data(l_train, l_dev, l_test)\n",
        "\n",
        "len(train_dataset), len(dev_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9439IezcCH7i"
      },
      "source": [
        "##***Model***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scceRefJp99M"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Flatten the predictions and labels to ignore padding (-100)\n",
        "    true_labels = []\n",
        "    true_preds = []\n",
        "\n",
        "    for label, pred in zip(labels.flatten(), preds.flatten()):\n",
        "        if label != -100:\n",
        "            true_labels.append(label)\n",
        "            true_preds.append(pred)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, true_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, true_preds, average='weighted')\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572,
          "referenced_widgets": [
            "e09d100e81e84df38571b0ff2284c265",
            "3d732dd76a9b40bfb1b720be1372d55f",
            "3373b6b8fdcf4b689d25881867195c9e",
            "412631cee32f4d448d779bcafc53e8a5",
            "cf3b69ccb2b44127a7f046361d79ac36",
            "5a87163c9e2746d38aaa0a24b2f35714",
            "f10e9d59f31e48c990422beb5eca21a6",
            "84c7517709ff4cd191cebb2b673523ae",
            "a48a5e5fd762421aa428c24e47c88318",
            "e74f89bf3fd44d419be9794adbca4d75",
            "88c6308aa64b42b18de152d605b991d8"
          ]
        },
        "id": "sNKZuYc8stxl",
        "outputId": "0f03b4fe-5000-4a0c-c692-72b8717de8a1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e09d100e81e84df38571b0ff2284c265",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11772' max='13565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11772/13565 33:28 < 05:05, 5.86 it/s, Epoch 4.34/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.547600</td>\n",
              "      <td>0.621758</td>\n",
              "      <td>0.776673</td>\n",
              "      <td>0.782050</td>\n",
              "      <td>0.776673</td>\n",
              "      <td>0.773964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.468900</td>\n",
              "      <td>0.538874</td>\n",
              "      <td>0.810560</td>\n",
              "      <td>0.817482</td>\n",
              "      <td>0.810560</td>\n",
              "      <td>0.808137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.431600</td>\n",
              "      <td>0.527149</td>\n",
              "      <td>0.827918</td>\n",
              "      <td>0.833603</td>\n",
              "      <td>0.827918</td>\n",
              "      <td>0.828375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.555555</td>\n",
              "      <td>0.831697</td>\n",
              "      <td>0.836229</td>\n",
              "      <td>0.831697</td>\n",
              "      <td>0.831736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13565' max='13565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13565/13565 38:45, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.547600</td>\n",
              "      <td>0.621758</td>\n",
              "      <td>0.776673</td>\n",
              "      <td>0.782050</td>\n",
              "      <td>0.776673</td>\n",
              "      <td>0.773964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.468900</td>\n",
              "      <td>0.538874</td>\n",
              "      <td>0.810560</td>\n",
              "      <td>0.817482</td>\n",
              "      <td>0.810560</td>\n",
              "      <td>0.808137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.431600</td>\n",
              "      <td>0.527149</td>\n",
              "      <td>0.827918</td>\n",
              "      <td>0.833603</td>\n",
              "      <td>0.827918</td>\n",
              "      <td>0.828375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.555555</td>\n",
              "      <td>0.831697</td>\n",
              "      <td>0.836229</td>\n",
              "      <td>0.831697</td>\n",
              "      <td>0.831736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.227500</td>\n",
              "      <td>0.591091</td>\n",
              "      <td>0.837387</td>\n",
              "      <td>0.841295</td>\n",
              "      <td>0.837387</td>\n",
              "      <td>0.837194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=13565, training_loss=0.3896432831504448, metrics={'train_runtime': 2326.9283, 'train_samples_per_second': 46.63, 'train_steps_per_second': 5.83, 'total_flos': 4569594615303300.0, 'train_loss': 0.3896432831504448, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
        "\n",
        "model = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label2id)+1)  # Adjust num_labels as needed\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTPJgfF7xylY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "e05cc4ad-6e4a-42d9-9d76-2675b8a06395"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='861' max='861' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [861/861 00:36]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6024723649024963,\n",
              " 'eval_accuracy': 0.8432245475047031,\n",
              " 'eval_precision': 0.8474981288091815,\n",
              " 'eval_recall': 0.8432245475047031,\n",
              " 'eval_f1': 0.8431260539738633,\n",
              " 'eval_runtime': 37.7603,\n",
              " 'eval_samples_per_second': 182.308,\n",
              " 'eval_steps_per_second': 22.802,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "trainer.evaluate(eval_dataset=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_preds_and_labels(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    true_preds = [\n",
        "      [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "      for prediction, label in zip(preds, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(preds, labels)\n",
        "    ]\n",
        "\n",
        "    return true_preds, true_labels\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "def random_sample_results(tokens, dataset, n=5):\n",
        "  random_indices = random.sample(range(len(dataset)), n)\n",
        "  sentences = [tokens[i] for i in random_indices]\n",
        "  tokens = [tokenizer.convert_ids_to_tokens(dataset[i]['input_ids']) for i in random_indices]\n",
        "\n",
        "  x = trainer.predict([dataset[i] for i in random_indices])\n",
        "  true_preds, true_labels = show_preds_and_labels(x)\n",
        "\n",
        "  for i, (sentence, token, pred, true) in enumerate(zip(sentences, tokens, true_preds, true_labels)):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print('ORG:       ', sentence)\n",
        "    print('Tokenized: ', [tk for tk in token if tk != '[CLS]' and tk != '[PAD]' and tk != '[SEP]'])\n",
        "    print('Pred:      ', pred)\n",
        "    print('truth:     ', true)\n",
        "    print()"
      ],
      "metadata": {
        "id": "fpFc5KNbt9Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_sample_results(test_tokens, test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "HO_2KsrauD8h",
        "outputId": "81fe6a84-ef55-4066-a41f-cb5010193f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1:\n",
            "ORG:        ['sunt', 'fere', 'cantionum', 'inventores', 'qui', 'stantia', 'carmen', 'incomitatum', 'relinquunt', 'quin', 'sibi', 'rithimi', 'concrepantiam', 'reddant']\n",
            "Tokenized:  ['sun', '##t', 'fe', '##re', 'can', '##tion', '##um', 'inventor', '##es', 'qui', 'stan', '##tia', 'carmen', 'inc', '##omi', '##tat', '##um', 're', '##lin', '##qu', '##unt', 'qui', '##n', 'si', '##bi', 'ri', '##thi', '##mi', 'con', '##cre', '##pan', '##tia', '##m', 'red', '##dant']\n",
            "Pred:       ['AUX', 'AUX', 'ADV', 'ADV', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', 'VERB', 'SCONJ', 'SCONJ', 'PRON', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB']\n",
            "truth:      ['AUX', 'AUX', 'ADV', 'ADV', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'VERB', 'VERB', 'VERB', 'VERB', 'SCONJ', 'SCONJ', 'PRON', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB']\n",
            "\n",
            "Sample 2:\n",
            "ORG:        ['◊õ÷¥÷º÷Ω◊ô', '◊û÷∑◊©÷∞◊Å◊ó÷¥◊™÷¥÷£◊ô◊ù', '◊ê÷≤◊†÷∑÷î◊ó÷∞◊†◊ï÷º', '◊û÷∏÷º◊ß÷π÷ñ◊ï◊ù', '◊ñ÷∂÷º÷ë◊î', '◊õ÷¥÷º÷Ω◊ô', '◊í÷∏÷Ω◊ì÷∞◊ú÷∏÷§◊î', '◊¶÷∑◊¢÷≤◊ß÷∏◊™÷∏', '◊ù÷ô', '◊§÷∞÷º◊†÷µ÷£◊ô', '◊ô÷∞◊î◊ï÷∏÷î◊î', '◊ô÷∞◊©÷∑◊Å◊ú÷∞÷º◊ó÷µ÷•', '◊†◊ï÷º', '◊ô÷∞◊î◊ï÷∏÷ñ◊î', '◊©÷∑◊Å◊ó÷≤◊™÷∏÷Ω', '◊î÷º']\n",
            "Tokenized:  ['◊õ', '##◊ô', '◊û', '##◊©', '##◊ó', '##◊™', '##◊ô', '##◊ù', '◊ê', '##◊†', '##◊ó', '##◊†', '##◊ï', '◊û', '##◊ß', '##◊ï', '##◊ù', '◊ñ', '##◊î', '◊õ', '##◊ô', '◊í', '##◊ì', '##◊ú', '##◊î', '◊¶', '##◊¢', '##◊ß', '##◊™', '◊ù', '◊§', '##◊†', '##◊ô', '◊ô', '##◊î', '##◊ï', '##◊î', '◊ô', '##◊©', '##◊ú', '##◊ó', '◊†', '##◊ï', '◊ô', '##◊î', '##◊ï', '##◊î', '◊©', '##◊ó', '##◊™', '◊î']\n",
            "Pred:       ['SCONJ', 'SCONJ', 'VERB', 'VERB', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'PRON', 'PRON', 'PRON', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'PRON', 'SCONJ', 'SCONJ', 'VERB', 'VERB', 'VERB', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'VERB', 'VERB', 'VERB', 'VERB', 'PRON', 'PRON', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'NOUN', 'NOUN', 'NOUN', 'PRON']\n",
            "truth:      ['SCONJ', 'SCONJ', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'PRON', 'PRON', 'PRON', 'PRON', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'PRON', 'SCONJ', 'SCONJ', 'VERB', 'VERB', 'VERB', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'VERB', 'VERB', 'VERB', 'VERB', 'PRON', 'PRON', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'VERB', 'VERB', 'VERB', 'PRON']\n",
            "\n",
            "Sample 3:\n",
            "ORG:        ['ÿ¶€á', 'ÿ¶Ÿàÿ™ŸÑÿßŸÇÿ™ÿß', 'ŸÜÿß⁄æÿßŸäŸâÿ™Ÿâ', '⁄ÜŸà⁄≠ŸÇ€áÿ±', 'ÿ¶Ÿàÿ±€ïŸÉ', 'Ÿæ€ïŸäÿØÿß', 'ŸÇŸâŸÑÿßŸÑÿßŸäÿØ€á']\n",
            "Tokenized:  ['[UNK]', 'Ÿä', '##Ÿà', '##ÿ™', '##ŸÑ', '##ÿß', '##ŸÇ', '##ÿ™', '##ÿß', 'ŸÜ', '##ÿß', '##⁄æ', '##ÿß', '##Ÿä', '##Ÿâ', '##ÿ™', '##Ÿâ', '[UNK]', '[UNK]', '[UNK]', '[UNK]']\n",
            "Pred:       ['NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'NOUN', 'NOUN', 'NOUN', 'VERB']\n",
            "truth:      ['PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADJ', 'NOUN', 'ADJ', 'VERB']\n",
            "\n",
            "Sample 4:\n",
            "ORG:        ['Yes', 'mine', 'too']\n",
            "Tokenized:  ['yes', 'mine', 'too']\n",
            "Pred:       ['INTJ', 'PRON', 'ADV']\n",
            "truth:      ['INTJ', 'PRON', 'ADV']\n",
            "\n",
            "Sample 5:\n",
            "ORG:        ['Ba≈üka', 'kadƒ±na', 'rastladƒ±', 'dedi', 'kadƒ±n']\n",
            "Tokenized:  ['bas', '##ka', 'ka', '##d', '##ƒ±', '##na', 'ras', '##tl', '##ad', '##ƒ±', 'de', '##di', 'ka', '##d', '##ƒ±', '##n']\n",
            "Pred:       ['ADJ', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'ADJ', 'ADJ', 'ADJ', 'ADJ']\n",
            "truth:      ['ADJ', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'ADJ', 'ADJ', 'ADJ', 'ADJ']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rm logs -r"
      ],
      "metadata": {
        "id": "JDPn-u0A3Hyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HilzBz9_q8I"
      },
      "source": [
        "#***Model Adjustment and Partial Freezing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozKSstN48LqP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Flatten the predictions and labels to ignore padding (-100)\n",
        "    true_labels = []\n",
        "    true_preds = []\n",
        "\n",
        "    for label, pred in zip(labels.flatten(), preds.flatten()):\n",
        "        if label != -100:\n",
        "            true_labels.append(label)\n",
        "            true_preds.append(pred)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, true_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, true_preds, average='weighted')\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "yxIey1mk-GR6",
        "outputId": "05644bed-a2bb-4f07-b5e4-ee3c7d0bfa1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13565' max='13565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13565/13565 23:14, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.880100</td>\n",
              "      <td>0.870613</td>\n",
              "      <td>0.663736</td>\n",
              "      <td>0.672899</td>\n",
              "      <td>0.663736</td>\n",
              "      <td>0.653944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.742300</td>\n",
              "      <td>0.726923</td>\n",
              "      <td>0.719536</td>\n",
              "      <td>0.729147</td>\n",
              "      <td>0.719536</td>\n",
              "      <td>0.713442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.642000</td>\n",
              "      <td>0.676921</td>\n",
              "      <td>0.745847</td>\n",
              "      <td>0.752280</td>\n",
              "      <td>0.745847</td>\n",
              "      <td>0.741745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.578900</td>\n",
              "      <td>0.642425</td>\n",
              "      <td>0.760317</td>\n",
              "      <td>0.765365</td>\n",
              "      <td>0.760317</td>\n",
              "      <td>0.758593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.509900</td>\n",
              "      <td>0.630568</td>\n",
              "      <td>0.766191</td>\n",
              "      <td>0.769941</td>\n",
              "      <td>0.766191</td>\n",
              "      <td>0.764041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=13565, training_loss=0.7004151577357213, metrics={'train_runtime': 1394.3028, 'train_samples_per_second': 77.82, 'train_steps_per_second': 9.729, 'total_flos': 4569594615303300.0, 'train_loss': 0.7004151577357213, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
        "\n",
        "model = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label2id)+1)  # Adjust num_labels as needed\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "for param in model.distilbert.embeddings.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Freeze the first 4 layers\n",
        "for param in model.distilbert.transformer.layer[:4].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "X44qpM_ULdRK",
        "outputId": "2a7f4fa3-0f1d-4b89-d873-7218cc2b223b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='861' max='861' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [861/861 00:36]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6348324418067932,\n",
              " 'eval_accuracy': 0.7739509937953518,\n",
              " 'eval_precision': 0.778746233678203,\n",
              " 'eval_recall': 0.7739509937953518,\n",
              " 'eval_f1': 0.7724361225287745,\n",
              " 'eval_runtime': 37.162,\n",
              " 'eval_samples_per_second': 185.243,\n",
              " 'eval_steps_per_second': 23.169,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "trainer.evaluate(eval_dataset=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "Ndvfa8xJQwmP",
        "outputId": "598255ab-b006-47d1-d0e9-4e6952a90cbe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1:\n",
            "ORG:        ['sunt', 'fere', 'cantionum', 'inventores', 'qui', 'stantia', 'carmen', 'incomitatum', 'relinquunt', 'quin', 'sibi', 'rithimi', 'concrepantiam', 'reddant']\n",
            "Tokenized:  ['sun', '##t', 'fe', '##re', 'can', '##tion', '##um', 'inventor', '##es', 'qui', 'stan', '##tia', 'carmen', 'inc', '##omi', '##tat', '##um', 're', '##lin', '##qu', '##unt', 'qui', '##n', 'si', '##bi', 'ri', '##thi', '##mi', 'con', '##cre', '##pan', '##tia', '##m', 'red', '##dant']\n",
            "Pred:       ['AUX', 'AUX', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', 'VERB', 'SCONJ', 'SCONJ', 'PRON', 'PRON', 'VERB', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', 'NOUN', 'NOUN', 'VERB', 'VERB']\n",
            "truth:      ['AUX', 'AUX', 'ADV', 'ADV', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'VERB', 'VERB', 'VERB', 'VERB', 'SCONJ', 'SCONJ', 'PRON', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB']\n",
            "\n",
            "Sample 2:\n",
            "ORG:        ['◊õ÷¥÷º÷Ω◊ô', '◊û÷∑◊©÷∞◊Å◊ó÷¥◊™÷¥÷£◊ô◊ù', '◊ê÷≤◊†÷∑÷î◊ó÷∞◊†◊ï÷º', '◊û÷∏÷º◊ß÷π÷ñ◊ï◊ù', '◊ñ÷∂÷º÷ë◊î', '◊õ÷¥÷º÷Ω◊ô', '◊í÷∏÷Ω◊ì÷∞◊ú÷∏÷§◊î', '◊¶÷∑◊¢÷≤◊ß÷∏◊™÷∏', '◊ù÷ô', '◊§÷∞÷º◊†÷µ÷£◊ô', '◊ô÷∞◊î◊ï÷∏÷î◊î', '◊ô÷∞◊©÷∑◊Å◊ú÷∞÷º◊ó÷µ÷•', '◊†◊ï÷º', '◊ô÷∞◊î◊ï÷∏÷ñ◊î', '◊©÷∑◊Å◊ó÷≤◊™÷∏÷Ω', '◊î÷º']\n",
            "Tokenized:  ['◊õ', '##◊ô', '◊û', '##◊©', '##◊ó', '##◊™', '##◊ô', '##◊ù', '◊ê', '##◊†', '##◊ó', '##◊†', '##◊ï', '◊û', '##◊ß', '##◊ï', '##◊ù', '◊ñ', '##◊î', '◊õ', '##◊ô', '◊í', '##◊ì', '##◊ú', '##◊î', '◊¶', '##◊¢', '##◊ß', '##◊™', '◊ù', '◊§', '##◊†', '##◊ô', '◊ô', '##◊î', '##◊ï', '##◊î', '◊ô', '##◊©', '##◊ú', '##◊ó', '◊†', '##◊ï', '◊ô', '##◊î', '##◊ï', '##◊î', '◊©', '##◊ó', '##◊™', '◊î']\n",
            "Pred:       ['SCONJ', 'SCONJ', 'VERB', 'VERB', 'VERB', 'VERB', 'NOUN', 'NOUN', 'PRON', 'PRON', 'VERB', 'VERB', 'VERB', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'PRON', 'SCONJ', 'SCONJ', 'NOUN', 'NOUN', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'VERB', 'VERB', 'VERB', 'VERB', 'PRON', 'PRON', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'NOUN', 'NOUN', 'NOUN', 'PRON']\n",
            "truth:      ['SCONJ', 'SCONJ', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'PRON', 'PRON', 'PRON', 'PRON', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'PRON', 'SCONJ', 'SCONJ', 'VERB', 'VERB', 'VERB', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'VERB', 'VERB', 'VERB', 'VERB', 'PRON', 'PRON', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'VERB', 'VERB', 'VERB', 'PRON']\n",
            "\n",
            "Sample 3:\n",
            "ORG:        ['ÿ¶€á', 'ÿ¶Ÿàÿ™ŸÑÿßŸÇÿ™ÿß', 'ŸÜÿß⁄æÿßŸäŸâÿ™Ÿâ', '⁄ÜŸà⁄≠ŸÇ€áÿ±', 'ÿ¶Ÿàÿ±€ïŸÉ', 'Ÿæ€ïŸäÿØÿß', 'ŸÇŸâŸÑÿßŸÑÿßŸäÿØ€á']\n",
            "Tokenized:  ['[UNK]', 'Ÿä', '##Ÿà', '##ÿ™', '##ŸÑ', '##ÿß', '##ŸÇ', '##ÿ™', '##ÿß', 'ŸÜ', '##ÿß', '##⁄æ', '##ÿß', '##Ÿä', '##Ÿâ', '##ÿ™', '##Ÿâ', '[UNK]', '[UNK]', '[UNK]', '[UNK]']\n",
            "Pred:       ['NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'NOUN', 'NOUN', 'VERB', 'VERB']\n",
            "truth:      ['PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADV', 'ADJ', 'NOUN', 'ADJ', 'VERB']\n",
            "\n",
            "Sample 4:\n",
            "ORG:        ['Yes', 'mine', 'too']\n",
            "Tokenized:  ['yes', 'mine', 'too']\n",
            "Pred:       ['INTJ', 'PRON', 'ADV']\n",
            "truth:      ['INTJ', 'PRON', 'ADV']\n",
            "\n",
            "Sample 5:\n",
            "ORG:        ['Ba≈üka', 'kadƒ±na', 'rastladƒ±', 'dedi', 'kadƒ±n']\n",
            "Tokenized:  ['bas', '##ka', 'ka', '##d', '##ƒ±', '##na', 'ras', '##tl', '##ad', '##ƒ±', 'de', '##di', 'ka', '##d', '##ƒ±', '##n']\n",
            "Pred:       ['ADJ', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'ADJ', 'ADJ', 'ADJ', 'ADJ']\n",
            "truth:      ['ADJ', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'ADJ', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'ADJ', 'ADJ', 'ADJ', 'ADJ']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "random_sample_results(test_tokens, test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e09d100e81e84df38571b0ff2284c265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d732dd76a9b40bfb1b720be1372d55f",
              "IPY_MODEL_3373b6b8fdcf4b689d25881867195c9e",
              "IPY_MODEL_412631cee32f4d448d779bcafc53e8a5"
            ],
            "layout": "IPY_MODEL_cf3b69ccb2b44127a7f046361d79ac36"
          }
        },
        "3d732dd76a9b40bfb1b720be1372d55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a87163c9e2746d38aaa0a24b2f35714",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f10e9d59f31e48c990422beb5eca21a6",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "3373b6b8fdcf4b689d25881867195c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c7517709ff4cd191cebb2b673523ae",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a48a5e5fd762421aa428c24e47c88318",
            "value": 267954768
          }
        },
        "412631cee32f4d448d779bcafc53e8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e74f89bf3fd44d419be9794adbca4d75",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_88c6308aa64b42b18de152d605b991d8",
            "value": "‚Äá268M/268M‚Äá[00:02&lt;00:00,‚Äá238MB/s]"
          }
        },
        "cf3b69ccb2b44127a7f046361d79ac36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a87163c9e2746d38aaa0a24b2f35714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10e9d59f31e48c990422beb5eca21a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c7517709ff4cd191cebb2b673523ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48a5e5fd762421aa428c24e47c88318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e74f89bf3fd44d419be9794adbca4d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c6308aa64b42b18de152d605b991d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}